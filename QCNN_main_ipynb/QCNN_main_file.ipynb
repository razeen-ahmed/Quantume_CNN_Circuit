{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Quantum Convolution Neural Network Circuit**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "F4GSCfZydaRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirement Text File Run"
      ],
      "metadata": {
        "id": "kIo_dcDYOQzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVz6qqDrOQNw",
        "outputId": "6f8ff629-d1a6-4347-f448-5985defe0a05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane==0.35.1 (from -r requirements.txt (line 1))\n",
            "  Downloading PennyLane-0.35.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting tensorflow==2.16.1 (from -r requirements.txt (line 2))\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting scikit-learn==1.4.2 (from -r requirements.txt (line 3))\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting medmnist==3.0.1 (from -r requirements.txt (line 4))\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch==2.2.2 (from -r requirements.txt (line 5))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting autograd==1.6.2 (from -r requirements.txt (line 6))\n",
            "  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (3.4.2)\n",
            "Collecting rustworkx (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.10.2)\n",
            "Collecting appdirs (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting semantic-version>=2.7 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.35 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1->-r requirements.txt (line 2))\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.68.0)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1->-r requirements.txt (line 2))\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (4.66.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (11.0.0)\n",
            "Collecting fire (from medmnist==3.0.1->-r requirements.txt (line 4))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd==1.6.2->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.13.1)\n",
            "INFO: pip is looking at multiple versions of pennylane-lightning to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pennylane-lightning>=0.35 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "  Downloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "  Downloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 5)) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from medmnist==3.0.1->-r requirements.txt (line 4))\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.1.2)\n",
            "Downloading PennyLane-0.35.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=86836bf64fb140f3c38e5c6912eb79628f56cee9326ac19b6642515f0b87a95d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: appdirs, triton, semantic-version, rustworkx, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, fire, autoray, autograd, tensorboard, scikit-learn, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, tensorflow, medmnist, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: autograd\n",
            "    Found existing installation: autograd 1.7.0\n",
            "    Uninstalling autograd-1.7.0:\n",
            "      Successfully uninstalled autograd-1.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.1\n",
            "    Uninstalling tensorboard-2.17.1:\n",
            "      Successfully uninstalled tensorboard-2.17.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.1\n",
            "    Uninstalling tensorflow-2.17.1:\n",
            "      Successfully uninstalled tensorflow-2.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.16.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 autograd-1.6.2 autoray-0.7.0 fire-0.7.0 medmnist-3.0.1 ml-dtypes-0.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 pennylane-0.35.1 pennylane-lightning-0.36.0 rustworkx-0.15.1 scikit-learn-1.4.2 semantic-version-2.10.0 tensorboard-2.16.2 tensorflow-2.16.1 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oxvjZijJJlGC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MwVIHtUQJVjb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, losses\n",
        "pca32 = ['pca32-1', 'pca32-2', 'pca32-3', 'pca32-4']\n",
        "autoencoder32 = ['autoencoder32-1', 'autoencoder32-2', 'autoencoder32-3', 'autoencoder32-4']\n",
        "pca30 = ['pca30-1', 'pca30-2', 'pca30-3', 'pca30-4']\n",
        "autoencoder30 = ['autoencoder30-1', 'autoencoder30-2', 'autoencoder30-3', 'autoencoder30-4']\n",
        "pca16 = ['pca16-1', 'pca16-2', 'pca16-3', 'pca16-4', 'pca16-compact']\n",
        "autoencoder16 = ['autoencoder16-1', 'autoencoder16-2', 'autoencoder16-3', 'autoencoder16-4', 'autoencoder16-compact']\n",
        "pca12 = ['pca12-1', 'pca12-2', 'pca12-3', 'pca12-4']\n",
        "autoencoder12 = ['autoencoder12-1', 'autoencoder12-2', 'autoencoder12-3', 'autoencoder12-4']\n",
        "\n",
        "def data_load_and_process(dataset, classes=[0, 1], feature_reduction='resize256', binary=True):\n",
        "    if dataset == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif dataset == 'mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
        "\n",
        "    if classes == 'odd_even':\n",
        "        odd = [1, 3, 5, 7, 9]\n",
        "        X_train = x_train\n",
        "        X_test = x_test\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y in odd else 0 for y in y_train]\n",
        "            Y_test = [1 if y in odd else 0 for y in y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y in odd else -1 for y in y_train]\n",
        "            Y_test = [1 if y in odd else -1 for y in y_test]\n",
        "\n",
        "    elif classes == '>4':\n",
        "        greater = [5, 6, 7, 8, 9]\n",
        "        X_train = x_train\n",
        "        X_test = x_test\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y in greater else 0 for y in y_train]\n",
        "            Y_test = [1 if y in greater else 0 for y in y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y in greater else -1 for y in y_train]\n",
        "            Y_test = [1 if y in greater else -1 for y in y_test]\n",
        "\n",
        "    else:\n",
        "        x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
        "        x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
        "\n",
        "        X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
        "        Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
        "\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y == classes[0] else 0 for y in Y_train]\n",
        "            Y_test = [1 if y == classes[0] else 0 for y in Y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y == classes[0] else -1 for y in Y_train]\n",
        "            Y_test = [1 if y == classes[0] else -1 for y in Y_test]\n",
        "\n",
        "    if feature_reduction == 'resize256':\n",
        "        X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
        "        X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
        "        X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "    elif feature_reduction == 'pca8' or feature_reduction in pca32 \\\n",
        "            or feature_reduction in pca30 or feature_reduction in pca16 or feature_reduction in pca12:\n",
        "\n",
        "        X_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
        "        X_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
        "        X_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
        "\n",
        "        if feature_reduction == 'pca8':\n",
        "            pca = PCA(8)\n",
        "        elif feature_reduction in pca32:\n",
        "            pca = PCA(32)\n",
        "        elif feature_reduction in pca30:\n",
        "            pca = PCA(30)\n",
        "        elif feature_reduction in pca16:\n",
        "            pca = PCA(16)\n",
        "        elif feature_reduction in pca12:\n",
        "            pca = PCA(12)\n",
        "\n",
        "\n",
        "        X_train = pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "\n",
        "        # Rescale for angle embedding\n",
        "        if feature_reduction == 'pca8' or feature_reduction == 'pca16-compact' or \\\n",
        "                feature_reduction in pca30 or feature_reduction in pca12:\n",
        "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())),\\\n",
        "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "    elif feature_reduction == 'autoencoder8' or feature_reduction in autoencoder32 \\\n",
        "            or feature_reduction in autoencoder30 or feature_reduction in autoencoder16 or feature_reduction in autoencoder12:\n",
        "        if feature_reduction == 'autoencoder8':\n",
        "            latent_dim = 8\n",
        "        elif feature_reduction in autoencoder32:\n",
        "            latent_dim = 32\n",
        "        elif feature_reduction in autoencoder30:\n",
        "            latent_dim = 30\n",
        "        elif feature_reduction in autoencoder16:\n",
        "            latent_dim = 16\n",
        "        elif feature_reduction in autoencoder12:\n",
        "            latent_dim = 12\n",
        "\n",
        "\n",
        "\n",
        "        class Autoencoder(Model):\n",
        "            def __init__(self, latent_dim):\n",
        "                super(Autoencoder, self).__init__()\n",
        "                self.latent_dim = latent_dim\n",
        "                self.encoder = tf.keras.Sequential([\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(latent_dim, activation='relu'),\n",
        "                ])\n",
        "                self.decoder = tf.keras.Sequential([\n",
        "                    layers.Dense(784, activation='sigmoid'),\n",
        "                    layers.Reshape((28, 28))\n",
        "                ])\n",
        "\n",
        "            def call(self, x):\n",
        "                encoded = self.encoder(x)\n",
        "                decoded = self.decoder(encoded)\n",
        "                return decoded\n",
        "\n",
        "        autoencoder = Autoencoder(latent_dim)\n",
        "\n",
        "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "        autoencoder.fit(X_train, X_train,\n",
        "                        epochs=10,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_test, X_test))\n",
        "\n",
        "        X_train, X_test = autoencoder.encoder(X_train).numpy(), autoencoder.encoder(X_test).numpy()\n",
        "\n",
        "        # Rescale for Angle Embedding\n",
        "        # Note this is not a rigorous rescaling method\n",
        "        if feature_reduction == 'autoencoder8' or feature_reduction == 'autoencoder16-compact' or\\\n",
        "                feature_reduction in autoencoder30 or feature_reduction in autoencoder12:\n",
        "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())), \\\n",
        "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
        "\n",
        "        return X_train, X_test, Y_train, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unitary\n",
        "---\n"
      ],
      "metadata": {
        "id": "3ILv-hupJ73K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This module contains the set of unitary ansatze that will be used to benchmark the performances of Quantum Convolutional Neural Network (QCNN) in QCNN.ipynb module\n",
        "import pennylane as qml\n",
        "\n",
        "# Unitary Ansatze for Convolutional Layer\n",
        "def U_TTN(params, wires):  # 2 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_5(params, wires):  # 10 params\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "    qml.RZ(params[2], wires=wires[0])\n",
        "    qml.RZ(params[3], wires=wires[1])\n",
        "    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n",
        "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[6], wires=wires[0])\n",
        "    qml.RX(params[7], wires=wires[1])\n",
        "    qml.RZ(params[8], wires=wires[0])\n",
        "    qml.RZ(params[9], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_6(params, wires):  # 10 params\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "    qml.RZ(params[2], wires=wires[0])\n",
        "    qml.RZ(params[3], wires=wires[1])\n",
        "    qml.CRX(params[4], wires=[wires[1], wires[0]])\n",
        "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[6], wires=wires[0])\n",
        "    qml.RX(params[7], wires=wires[1])\n",
        "    qml.RZ(params[8], wires=wires[0])\n",
        "    qml.RZ(params[9], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_9(params, wires):  # 2 params\n",
        "    qml.Hadamard(wires=wires[0])\n",
        "    qml.Hadamard(wires=wires[1])\n",
        "    qml.CZ(wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_13(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[3], wires=wires[0])\n",
        "    qml.RY(params[4], wires=wires[1])\n",
        "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_14(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CRX(params[2], wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[3], wires=wires[0])\n",
        "    qml.RY(params[4], wires=wires[1])\n",
        "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_15(params, wires):  # 4 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[2], wires=wires[0])\n",
        "    qml.RY(params[3], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_SO4(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[2], wires=wires[0])\n",
        "    qml.RY(params[3], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[4], wires=wires[0])\n",
        "    qml.RY(params[5], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_SU4(params, wires): # 15 params\n",
        "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
        "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[6], wires=wires[0])\n",
        "    qml.RZ(params[7], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[8], wires=wires[0])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
        "    qml.U3(params[12], params[13], params[14], wires=wires[1])\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "def Pooling_ansatz1(params, wires): #2 params\n",
        "    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRX(params[1], wires=[wires[0], wires[1]])\n",
        "\n",
        "def Pooling_ansatz2(wires): #0 params\n",
        "    qml.CRZ(wires=[wires[0], wires[1]])\n",
        "\n",
        "def Pooling_ansatz3(*params, wires): #3 params\n",
        "    qml.CRot(*params, wires=[wires[0], wires[1]])\n"
      ],
      "metadata": {
        "id": "3IsZAmLILPsU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Angular Hybrid\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "oH6g6UENLUIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an implementation of an alternative Mottonen State Preparation to avoid normalization problem.\n",
        "import pennylane as qml\n",
        "\n",
        "# 3 bits of information is embedded in 2 wires\n",
        "def Angular_Hybrid_2(X, wires):\n",
        "    qml.RY(X[0], wires=wires[0])\n",
        "\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
        "\n",
        "# 15 bits of information is embedded in 4 wires\n",
        "def Angular_Hybrid_4(X, wires):\n",
        "    qml.RY(X[0], wires=wires[0])\n",
        "\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
        "\n",
        "    qml.RY(X[3], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[1], wires[2]])\n",
        "    qml.RY(X[4], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[0], wires[2]])\n",
        "    qml.RY(X[5], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[1], wires[2]])\n",
        "    qml.RY(X[6], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[0], wires[2]])\n",
        "\n",
        "    qml.RY(X[7], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[8], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[1], wires[3]])\n",
        "    qml.RY(X[9], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[10], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[0], wires[3]])\n",
        "    qml.RY(X[11], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[12], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[1], wires[3]])\n",
        "    qml.RY(X[13], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[14], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[0], wires[3]])"
      ],
      "metadata": {
        "id": "jZng9fLDL_tB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MVAmWz1fJ3hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an implementation of data_embedding function used for 8 qubits Quantum Convolutional Neural Network (QCNN)\n",
        "# and Hierarchical Quantum Classifier circuit.\n",
        "import pennylane as qml\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
        "from pennylane.templates.state_preparations import MottonenStatePreparation\n",
        "import numpy as np\n",
        "\n",
        "def data_embedding(X, embedding_type='Amplitude'):\n",
        "    if embedding_type == 'Amplitude':\n",
        "        AmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
        "    elif embedding_type == 'Angle':\n",
        "        AngleEmbedding(X, wires=range(8), rotation='Y')\n",
        "    elif embedding_type == 'Angle-compact':\n",
        "        AngleEmbedding(X[:8], wires=range(8), rotation='X')\n",
        "        AngleEmbedding(X[8:16], wires=range(8), rotation='Y')\n",
        "\n",
        "    # Hybrid Direct Embedding (HDE)\n",
        "    elif embedding_type == 'Amplitude-Hybrid4-1' or embedding_type == 'Amplitude-Hybrid4-2' or \\\n",
        "            embedding_type == 'Amplitude-Hybrid4-3' or embedding_type == 'Amplitude-Hybrid4-4':\n",
        "        X1 = X[:2 ** 4]\n",
        "        X2 = X[2 ** 4:2 ** 5]\n",
        "        norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
        "        X1, X2 = X1 / norm_X1, X2 / norm_X2\n",
        "\n",
        "        if embedding_type == 'Amplitude-Hybrid4-1':\n",
        "            MottonenStatePreparation(X1, wires=[0, 1, 2, 3])\n",
        "            MottonenStatePreparation(X2, wires=[4, 5, 6, 7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-2':\n",
        "            MottonenStatePreparation(X1, wires=[0, 2, 4, 6])\n",
        "            MottonenStatePreparation(X2, wires=[1, 3, 5, 7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-3':\n",
        "            MottonenStatePreparation(X1, wires=[0, 1, 6, 7])\n",
        "            MottonenStatePreparation(X2, wires=[2, 3, 4, 5])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-4':\n",
        "            MottonenStatePreparation(X1, wires=[0, 3, 4, 7])\n",
        "            MottonenStatePreparation(X2, wires=[1, 2, 5, 6])\n",
        "\n",
        "    elif embedding_type == 'Amplitude-Hybrid2-1' or embedding_type == 'Amplitude-Hybrid2-2' \\\n",
        "            or embedding_type == 'Amplitude-Hybrid2-3' or embedding_type == 'Amplitude-Hybrid2-4':\n",
        "        X1 = X[:4]\n",
        "        X2 = X[4:8]\n",
        "        X3 = X[8:12]\n",
        "        X4 = X[12:16]\n",
        "        norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(X3), np.linalg.norm(\n",
        "            X4)\n",
        "        X1, X2, X3, X4 = X1 / norm_X1, X2 / norm_X2, X3 / norm_X3, X4 / norm_X4\n",
        "\n",
        "        if embedding_type == 'Amplitude-Hybrid2-1':\n",
        "            MottonenStatePreparation(X1, wires=[0,1])\n",
        "            MottonenStatePreparation(X2, wires=[2,3])\n",
        "            MottonenStatePreparation(X3, wires=[4,5])\n",
        "            MottonenStatePreparation(X4, wires=[6,7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-2':\n",
        "            MottonenStatePreparation(X1, wires=[0,4])\n",
        "            MottonenStatePreparation(X2, wires=[1,5])\n",
        "            MottonenStatePreparation(X3, wires=[2,6])\n",
        "            MottonenStatePreparation(X4, wires=[3,7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-3':\n",
        "            MottonenStatePreparation(X1, wires=[0,7])\n",
        "            MottonenStatePreparation(X2, wires=[1,6])\n",
        "            MottonenStatePreparation(X3, wires=[2,5])\n",
        "            MottonenStatePreparation(X4, wires=[3,4])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-4':\n",
        "            MottonenStatePreparation(X1, wires=[0,2])\n",
        "            MottonenStatePreparation(X2, wires=[1,3])\n",
        "            MottonenStatePreparation(X3, wires=[4,6])\n",
        "            MottonenStatePreparation(X4, wires=[5,7])\n",
        "\n",
        "    # Hybrid Angle Embedding (HAE)\n",
        "    elif embedding_type == 'Angular-Hybrid4-1' or embedding_type == 'Angular-Hybrid4-2' or \\\n",
        "            embedding_type == 'Angular-Hybrid4-3' or embedding_type == 'Angular-Hybrid4-4':\n",
        "        N = 15 # 15 classical data in 4 qubits\n",
        "        X1 = X[:N]\n",
        "        X2 = X[N:2*N]\n",
        "\n",
        "        if embedding_type == 'Angular-Hybrid4-1':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 1, 2, 3])\n",
        "            Angular_Hybrid_4(X2, wires=[4, 5, 6, 7])\n",
        "        elif embedding_type == 'Angular-Hybrid4-2':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 2, 4, 6])\n",
        "            Angular_Hybrid_4(X2, wires=[1, 3, 5, 7])\n",
        "        elif embedding_type == 'Angular-Hybrid4-3':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 1, 6, 7])\n",
        "            Angular_Hybrid_4(X2, wires=[2, 3, 4, 5])\n",
        "        elif embedding_type == 'Angular-Hybrid4-4':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 3, 4, 7])\n",
        "            Angular_Hybrid_4(X2, wires=[1, 2, 5, 6])\n",
        "\n",
        "    elif embedding_type == 'Angular-Hybrid2-1' or embedding_type == 'Angular-Hybrid2-2' \\\n",
        "            or embedding_type == 'Angular-Hybrid2-3' or embedding_type == 'Angular-Hybrid2-4':\n",
        "        N = 3  # 3 classical bits in 2 qubits\n",
        "        X1 = X[:N]\n",
        "        X2 = X[N:2*N]\n",
        "        X3 = X[2*N:3*N]\n",
        "        X4 = X[3*N:4*N]\n",
        "\n",
        "        if embedding_type == 'Angular-Hybrid2-1':\n",
        "            Angular_Hybrid_2(X1, wires=[0,1])\n",
        "            Angular_Hybrid_2(X2, wires=[2,3])\n",
        "            Angular_Hybrid_2(X3, wires=[4,5])\n",
        "            Angular_Hybrid_2(X4, wires=[6,7])\n",
        "        elif embedding_type == 'Angular-Hybrid2-2':\n",
        "            Angular_Hybrid_2(X1, wires=[0,4])\n",
        "            Angular_Hybrid_2(X2, wires=[1,5])\n",
        "            Angular_Hybrid_2(X3, wires=[2,6])\n",
        "            Angular_Hybrid_2(X4, wires=[3,7])\n",
        "        elif embedding_type == 'Angular-Hybrid2-3':\n",
        "            Angular_Hybrid_2(X1, wires=[0,7])\n",
        "            Angular_Hybrid_2(X2, wires=[1,6])\n",
        "            Angular_Hybrid_2(X3, wires=[2,5])\n",
        "            Angular_Hybrid_2(X4, wires=[3,4])\n",
        "        elif embedding_type == 'Angular-Hybrid2-4':\n",
        "            Angular_Hybrid_2(X1, wires=[0,2])\n",
        "            Angular_Hybrid_2(X2, wires=[1,3])\n",
        "            Angular_Hybrid_2(X3, wires=[4,6])\n",
        "            Angular_Hybrid_2(X4, wires=[5,7])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bRtqedsTKVu7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QCNN Circuit"
      ],
      "metadata": {
        "id": "pOrO5jiKKGKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "# import unitary\n",
        "# import embedding\n",
        "\n",
        "# Quantum Circuits for Convolutional layers\n",
        "def conv_layer1(U, params):\n",
        "    U(params, wires=[0, 7])\n",
        "    for i in range(0, 8, 2):\n",
        "        U(params, wires=[i, i + 1])\n",
        "    for i in range(1, 7, 2):\n",
        "        U(params, wires=[i, i + 1])\n",
        "def conv_layer2(U, params):\n",
        "    U(params, wires=[0, 6])\n",
        "    U(params, wires=[0, 2])\n",
        "    U(params, wires=[4, 6])\n",
        "    U(params, wires=[2, 4])\n",
        "def conv_layer3(U, params):\n",
        "    U(params, wires=[0,4])\n",
        "\n",
        "# Quantum Circuits for Pooling layers\n",
        "def pooling_layer1(V, params):\n",
        "    for i in range(0, 8, 2):\n",
        "        V(params, wires=[i + 1, i])\n",
        "def pooling_layer2(V, params):\n",
        "    V(params, wires=[2,0])\n",
        "    V(params, wires=[6,4])\n",
        "def pooling_layer3(V, params):\n",
        "    V(params, wires=[0,4])\n",
        "\n",
        "\n",
        "\n",
        "def QCNN_structure(U, params, U_params):\n",
        "    param1 = params[0:U_params]\n",
        "    param2 = params[U_params: 2 * U_params]\n",
        "    param3 = params[2 * U_params: 3 * U_params]\n",
        "    param4 = params[3 * U_params: 3 * U_params + 2]\n",
        "    param5 = params[3 * U_params + 2: 3 * U_params + 4]\n",
        "    param6 = params[3 * U_params + 4: 3 * U_params + 6]\n",
        "\n",
        "    # Pooling Ansatz1 is used by default\n",
        "    conv_layer1(U, param1)\n",
        "    pooling_layer1(Pooling_ansatz1, param4)\n",
        "    conv_layer2(U, param2)\n",
        "    pooling_layer2(Pooling_ansatz1, param5)\n",
        "    conv_layer3(U, param3)\n",
        "    pooling_layer3(Pooling_ansatz1, param6)\n",
        "\n",
        "\n",
        "def QCNN_structure_without_pooling(U, params, U_params):\n",
        "    param1 = params[0:U_params]\n",
        "    param2 = params[U_params: 2 * U_params]\n",
        "    param3 = params[2 * U_params: 3 * U_params]\n",
        "\n",
        "    conv_layer1(U, param1)\n",
        "    conv_layer2(U, param2)\n",
        "    conv_layer3(U, param3)\n",
        "\n",
        "def QCNN_1D_circuit(U, params, U_params):\n",
        "    param1 = params[0: U_params]\n",
        "    param2 = params[U_params: 2*U_params]\n",
        "    param3 = params[2*U_params: 3*U_params]\n",
        "\n",
        "    for i in range(0, 8, 2):\n",
        "        U(param1, wires=[i, i + 1])\n",
        "    for i in range(1, 7, 2):\n",
        "        U(param1, wires=[i, i + 1])\n",
        "\n",
        "    U(param2, wires=[2,3])\n",
        "    U(param2, wires=[4,5])\n",
        "    U(param3, wires=[3,4])\n",
        "\n",
        "\n",
        "\n",
        "dev = qml.device('default.qubit', wires = 8)\n",
        "@qml.qnode(dev)\n",
        "def QCNN(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
        "\n",
        "\n",
        "    # Data Embedding\n",
        "    data_embedding(X, embedding_type=embedding_type)\n",
        "\n",
        "    # Quantum Convolutional Neural Network\n",
        "    if U == 'U_TTN':\n",
        "        QCNN_structure(U_TTN, params, U_params)\n",
        "    elif U == 'U_5':\n",
        "        QCNN_structure(U_5, params, U_params)\n",
        "    elif U == 'U_6':\n",
        "        QCNN_structure(U_6, params, U_params)\n",
        "    elif U == 'U_9':\n",
        "        QCNN_structure(U_9, params, U_params)\n",
        "    elif U == 'U_13':\n",
        "        QCNN_structure(U_13, params, U_params)\n",
        "    elif U == 'U_14':\n",
        "        QCNN_structure(U_14, params, U_params)\n",
        "    elif U == 'U_15':\n",
        "        QCNN_structure(U_15, params, U_params)\n",
        "    elif U == 'U_SO4':\n",
        "        QCNN_structure(U_SO4, params, U_params)\n",
        "    elif U == 'U_SU4':\n",
        "        QCNN_structure(U_SU4, params, U_params)\n",
        "    elif U == 'U_SU4_no_pooling':\n",
        "        QCNN_structure_without_pooling(U_SU4, params, U_params)\n",
        "    elif U == 'U_SU4_1D':\n",
        "        QCNN_1D_circuit(U_SU4, params, U_params)\n",
        "    elif U == 'U_9_1D':\n",
        "        QCNN_1D_circuit(U_9, params, U_params)\n",
        "    else:\n",
        "        print(\"Invalid Unitary Ansatze\")\n",
        "        return False\n",
        "\n",
        "    if cost_fn == 'mse':\n",
        "        result = qml.expval(qml.PauliZ(4))\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        result = qml.probs(wires=4)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "2ZPP4if2MKkx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hierarchial Circuit\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ws2vLPbEMW4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementaion of Hierarchical Quantum Classifier Structure.\n",
        "import pennylane as qml\n",
        "# import unitary\n",
        "# import embedding\n",
        "\n",
        "dev_TTN = qml.device('default.qubit', wires=8)\n",
        "\n",
        "def Hierarchical_structure(U, params, U_params):\n",
        "    param1 = params[0 * U_params:1 * U_params]\n",
        "    param2 = params[1 * U_params:2 * U_params]\n",
        "    param3 = params[2 * U_params:3 * U_params]\n",
        "    param4 = params[3 * U_params:4 * U_params]\n",
        "    param5 = params[4 * U_params:5 * U_params]\n",
        "    param6 = params[5 * U_params:6 * U_params]\n",
        "    param7 = params[6 * U_params:7 * U_params]\n",
        "\n",
        "    # 1st Layer\n",
        "    U(param1, wires=[0, 1])\n",
        "    U(param2, wires=[2, 3])\n",
        "    U(param3, wires=[4, 5])\n",
        "    U(param4, wires=[6, 7])\n",
        "    # 2nd Layer\n",
        "    U(param5, wires=[1, 3])\n",
        "    U(param6, wires=[5, 7])\n",
        "    # 3rd Layer\n",
        "    U(param7, wires=[3, 7])\n",
        "\n",
        "\n",
        "\n",
        "@qml.qnode(dev_TTN)\n",
        "def Hierarchical_classifier(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
        "    data_embedding(X, embedding_type=embedding_type)\n",
        "    if U == 'U_TTN':\n",
        "        Hierarchical_structure(U_TTN, params, U_params)\n",
        "    elif U == 'U_5':\n",
        "        Hierarchical_structure(U_5, params, U_params)\n",
        "    elif U == 'U_6':\n",
        "        Hierarchical_structure(U_6, params, U_params)\n",
        "    elif U == 'U_9':\n",
        "        Hierarchical_structure(U_9, params, U_params)\n",
        "    elif U == 'U_13':\n",
        "        Hierarchical_structure(U_13, params, U_params)\n",
        "    elif U == 'U_14':\n",
        "        Hierarchical_structure(U_14, params, U_params)\n",
        "    elif U == 'U_15':\n",
        "        Hierarchical_structure(U_15, params, U_params)\n",
        "    elif U == 'U_SO4':\n",
        "        Hierarchical_structure(U_SO4, params, U_params)\n",
        "    elif U == 'U_SU4':\n",
        "        Hierarchical_structure(U_SU4, params, U_params)\n",
        "    else:\n",
        "        print(\"Invalid Unitary Ansatz\")\n",
        "        return False\n",
        "    if cost_fn == 'mse':\n",
        "        result = qml.expval(qml.PauliZ(7))\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        result = qml.probs(wires=7)\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "aLrAQP8nMjjS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "jap0PhFiJxfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of Quantum circuit training procedure\n",
        "# import QCNN_circuit\n",
        "# import Hierarchical_circuit\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import autograd.numpy as anp\n",
        "\n",
        "import pennylane.numpy as qnp #new line added 11/25/24\n",
        "\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "def cross_entropy(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        c_entropy = l * (anp.log(p[l])) + (1 - l) * anp.log(1 - p[1 - l])\n",
        "        loss = loss + c_entropy\n",
        "    return -1 * loss\n",
        "\n",
        "def cost(params, X, Y, U, U_params, embedding_type, circuit, cost_fn):\n",
        "    if circuit == 'QCNN':\n",
        "        predictions = [QCNN(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
        "    elif circuit == 'Hierarchical':\n",
        "        predictions = [Hierarchical_classifier(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
        "\n",
        "    if cost_fn == 'mse':\n",
        "        loss = square_loss(Y, predictions)\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        loss = cross_entropy(Y, predictions)\n",
        "    return loss\n",
        "\n",
        "# Circuit training parameters\n",
        "steps = 200\n",
        "learning_rate = 0.01\n",
        "batch_size = 25\n",
        "def circuit_training(X_train, Y_train, U, U_params, embedding_type, circuit, cost_fn):\n",
        "    if circuit == 'QCNN':\n",
        "        if U == 'U_SU4_no_pooling' or U == 'U_SU4_1D' or U == 'U_9_1D':\n",
        "            total_params = U_params * 3\n",
        "        else:\n",
        "            total_params = U_params * 3 + 2 * 3\n",
        "    elif circuit == 'Hierarchical':\n",
        "        total_params = U_params * 7\n",
        "    # params = qnp.random.randn(total_params, requires_grad=True)\n",
        "    params = qnp.random.randn(total_params, requires_grad=True)\n",
        "    opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
        "    loss_history = []\n",
        "\n",
        "    for it in range(steps):\n",
        "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "        X_batch = [X_train[i] for i in batch_index]\n",
        "        Y_batch = [Y_train[i] for i in batch_index]\n",
        "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit, cost_fn),\n",
        "                                                     params)\n",
        "        loss_history.append(cost_new)\n",
        "        if it % 10 == 0:\n",
        "            print(\"iteration: \", it, \" cost: \", cost_new)\n",
        "    return loss_history, params\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ll5uj6MMKQ8M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking\n",
        "---"
      ],
      "metadata": {
        "id": "j6Hi3FzUKRPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import data\n",
        "# import Training\n",
        "# import QCNN_circuit\n",
        "# import Hierarchical_circuit\n",
        "import numpy as np\n",
        "\n",
        "def accuracy_test(predictions, labels, cost_fn, binary = True):\n",
        "    if cost_fn == 'mse':\n",
        "        if binary == True:\n",
        "            acc = 0\n",
        "            for l, p in zip(labels, predictions):\n",
        "                if np.abs(l - p) < 1:\n",
        "                    acc = acc + 1\n",
        "            return acc / len(labels)\n",
        "\n",
        "        else:\n",
        "            acc = 0\n",
        "            for l, p in zip(labels, predictions):\n",
        "                if np.abs(l - p) < 0.5:\n",
        "                    acc = acc + 1\n",
        "            return acc / len(labels)\n",
        "\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        acc = 0\n",
        "        for l,p in zip(labels, predictions):\n",
        "            if p[0] > p[1]:\n",
        "                P = 0\n",
        "            else:\n",
        "                P = 1\n",
        "            if P == l:\n",
        "                acc = acc + 1\n",
        "        return acc / len(labels)\n",
        "\n",
        "\n",
        "def Encoding_to_Embedding(Encoding):\n",
        "    # Amplitude Embedding / Angle Embedding\n",
        "    if Encoding == 'resize256':\n",
        "        Embedding = 'Amplitude'\n",
        "    elif Encoding == 'pca8':\n",
        "        Embedding = 'Angle'\n",
        "    elif Encoding == 'autoencoder8':\n",
        "        Embedding = 'Angle'\n",
        "\n",
        "    # Amplitude Hybrid Embedding\n",
        "    # 4 qubit block\n",
        "    elif Encoding == 'pca32-1':\n",
        "        Embedding = 'Amplitude-Hybrid4-1'\n",
        "    elif Encoding == 'autoencoder32-1':\n",
        "        Embedding = 'Amplitude-Hybrid4-1'\n",
        "\n",
        "    elif Encoding == 'pca32-2':\n",
        "        Embedding = 'Amplitude-Hybrid4-2'\n",
        "    elif Encoding == 'autoencoder32-2':\n",
        "        Embedding = 'Amplitude-Hybrid4-2'\n",
        "\n",
        "    elif Encoding == 'pca32-3':\n",
        "        Embedding = 'Amplitude-Hybrid4-3'\n",
        "    elif Encoding == 'autoencoder32-3':\n",
        "        Embedding = 'Amplitude-Hybrid4-3'\n",
        "\n",
        "    elif Encoding == 'pca32-4':\n",
        "        Embedding = 'Amplitude-Hybrid4-4'\n",
        "    elif Encoding == 'autoencoder32-4':\n",
        "        Embedding = 'Amplitude-Hybrid4-4'\n",
        "\n",
        "    # 2 qubit block\n",
        "    elif Encoding == 'pca16-1':\n",
        "        Embedding = 'Amplitude-Hybrid2-1'\n",
        "    elif Encoding == 'autoencoder16-1':\n",
        "        Embedding = 'Amplitude-Hybrid2-1'\n",
        "\n",
        "    elif Encoding == 'pca16-2':\n",
        "        Embedding = 'Amplitude-Hybrid2-2'\n",
        "    elif Encoding == 'autoencoder16-2':\n",
        "        Embedding = 'Amplitude-Hybrid2-2'\n",
        "\n",
        "    elif Encoding == 'pca16-3':\n",
        "        Embedding = 'Amplitude-Hybrid2-3'\n",
        "    elif Encoding == 'autoencoder16-3':\n",
        "        Embedding = 'Amplitude-Hybrid2-3'\n",
        "\n",
        "    elif Encoding == 'pca16-4':\n",
        "        Embedding = 'Amplitude-Hybrid2-4'\n",
        "    elif Encoding == 'autoencoder16-4':\n",
        "        Embedding = 'Amplitude-Hybrid2-4'\n",
        "\n",
        "    # Angular HybridEmbedding\n",
        "    # 4 qubit block\n",
        "    elif Encoding == 'pca30-1':\n",
        "        Embedding = 'Angular-Hybrid4-1'\n",
        "    elif Encoding == 'autoencoder30-1':\n",
        "        Embedding = 'Angular-Hybrid4-1'\n",
        "\n",
        "    elif Encoding == 'pca30-2':\n",
        "        Embedding = 'Angular-Hybrid4-2'\n",
        "    elif Encoding == 'autoencoder30-2':\n",
        "        Embedding = 'Angular-Hybrid4-2'\n",
        "\n",
        "    elif Encoding == 'pca30-3':\n",
        "        Embedding = 'Angular-Hybrid4-3'\n",
        "    elif Encoding == 'autoencoder30-3':\n",
        "        Embedding = 'Angular-Hybrid4-3'\n",
        "\n",
        "    elif Encoding == 'pca30-4':\n",
        "        Embedding = 'Angular-Hybrid4-4'\n",
        "    elif Encoding == 'autoencoder30-4':\n",
        "        Embedding = 'Angular-Hybrid4-4'\n",
        "\n",
        "    # 2 qubit block\n",
        "    elif Encoding == 'pca12-1':\n",
        "        Embedding = 'Angular-Hybrid2-1'\n",
        "    elif Encoding == 'autoencoder12-1':\n",
        "        Embedding = 'Angular-Hybrid2-1'\n",
        "\n",
        "    elif Encoding == 'pca12-2':\n",
        "        Embedding = 'Angular-Hybrid2-2'\n",
        "    elif Encoding == 'autoencoder12-2':\n",
        "        Embedding = 'Angular-Hybrid2-2'\n",
        "\n",
        "    elif Encoding == 'pca12-3':\n",
        "        Embedding = 'Angular-Hybrid2-3'\n",
        "    elif Encoding == 'autoencoder12-3':\n",
        "        Embedding = 'Angular-Hybrid2-3'\n",
        "\n",
        "    elif Encoding == 'pca12-4':\n",
        "        Embedding = 'Angular-Hybrid2-4'\n",
        "    elif Encoding == 'autoencoder12-4':\n",
        "        Embedding = 'Angular-Hybrid2-4'\n",
        "\n",
        "    # Two Gates Compact Encoding\n",
        "    elif Encoding == 'pca16-compact':\n",
        "        Embedding = 'Angle-compact'\n",
        "    elif Encoding == 'autoencoder16-compact':\n",
        "        Embedding = 'Angle-compact'\n",
        "    return Embedding\n",
        "\n",
        "\n",
        "def Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit, cost_fn, binary=True):\n",
        "    I = len(Unitaries)\n",
        "    J = len(Encodings)\n",
        "\n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            f = open('result.txt', 'a+')\n",
        "            U = Unitaries[i]\n",
        "            U_params = U_num_params[i]\n",
        "            Encoding = Encodings[j]\n",
        "            Embedding = Encoding_to_Embedding(Encoding)\n",
        "\n",
        "            X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
        "                                                                          feature_reduction=Encoding, binary=binary)\n",
        "\n",
        "            print(\"\\n\")\n",
        "            print(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
        "            loss_history, trained_params = circuit_training(X_train, Y_train, U, U_params, Embedding, circuit, cost_fn)\n",
        "\n",
        "            if circuit == 'QCNN':\n",
        "                predictions = [QCNN(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
        "            elif circuit == 'Hierarchical':\n",
        "                predictions = [Hierarchical_classifier(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
        "\n",
        "            accuracy = accuracy_test(predictions, Y_test, cost_fn, binary)\n",
        "            print(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
        "\n",
        "            f.write(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
        "            f.write(\"\\n\")\n",
        "            f.write(str(loss_history))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "def Data_norm(dataset, classes, Encodings, binary=True):\n",
        "    J = len(Encodings)\n",
        "    Num_data = 10000\n",
        "\n",
        "    f = open('Result/data_norm.txt', '+a')\n",
        "\n",
        "    for j in range(J):\n",
        "        Encoding = Encodings[j]\n",
        "\n",
        "        X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
        "                                                                          feature_reduction=Encoding, binary=binary)\n",
        "\n",
        "        if Encoding == 'pca32-3' or Encoding == 'autoencoder32-3':\n",
        "            norms_X1 = []\n",
        "            norms_X2 = []\n",
        "            for i in range(Num_data):\n",
        "                index = np.random.randint(0, len(X_train))\n",
        "                X = X_train[index]\n",
        "\n",
        "                X1 = X[:2 ** 4]\n",
        "                X2 = X[2 ** 4:2 ** 5]\n",
        "                norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
        "                norms_X1.append(norm_X1)\n",
        "                norms_X2.append(norm_X2)\n",
        "\n",
        "            norms_X1, norms_X2 = np.array(norms_X1), np.array(norms_X2)\n",
        "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
        "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
        "\n",
        "            if Encoding == 'pca32-3':\n",
        "                f.write(\"PCA32 Encoding\\n\")\n",
        "            elif Encoding == 'autoencoder32-3':\n",
        "                f.write(\"autoencoder32 Encoding\\n\")\n",
        "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        elif Encoding == 'pca16' or Encoding == 'autoencoder16':\n",
        "            norms_X1 = []\n",
        "            norms_X2 = []\n",
        "            norms_X3 = []\n",
        "            norms_X4 = []\n",
        "            for i in range(Num_data):\n",
        "                index = np.random.randint(0, len(X_train))\n",
        "                X = X_train[index]\n",
        "\n",
        "                X1 = X[:4]\n",
        "                X2 = X[4:8]\n",
        "                X3 = X[8:12]\n",
        "                X4 = X[12:16]\n",
        "                norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(\n",
        "                    X3), np.linalg.norm(X4)\n",
        "\n",
        "                norms_X1.append(norm_X1)\n",
        "                norms_X2.append(norm_X2)\n",
        "                norms_X3.append(norm_X3)\n",
        "                norms_X4.append(norm_X4)\n",
        "\n",
        "            norms_X1, norms_X2, norms_X3, norms_X4 = np.array(norms_X1), np.array(norms_X2), np.array(norms_X3), np.array(norms_X4)\n",
        "\n",
        "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
        "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
        "            mean_X3, stdev_X3 = np.mean(norms_X3), np.std(norms_X3)\n",
        "            mean_X4, stdev_X4 = np.mean(norms_X4), np.std(norms_X4)\n",
        "\n",
        "            if Encoding == 'pca16':\n",
        "                f.write(\"PCA16 Encoding\\n\")\n",
        "            elif Encoding == 'autoencoder16':\n",
        "                f.write(\"autoencoder16 Encoding\\n\")\n",
        "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X3: \" + str(mean_X3) + \" standard deviation of X3: \" + str(stdev_X3))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X4: \" + str(mean_X4) + \" standard deviation of X4: \" + str(stdev_X4))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    f.close()\n"
      ],
      "metadata": {
        "id": "NVigoAR9KdMa"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "YYTMzefHKdko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This generates the results of the bechmarking code\n",
        "\n",
        "# import Benchmarking\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Here are possible combinations of benchmarking user could try.\n",
        "Unitaries: ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4', 'U_SU4', 'U_SU4_no_pooling', 'U_SU4_1D', 'U_9_1D']\n",
        "U_num_params: [2, 10, 10, 2, 6, 6, 4, 6, 15, 15, 15, 2]\n",
        "Encodings: ['resize256', 'pca8', 'autoencoder8', 'pca16-compact', 'autoencoder16-compact', 'pca32-1', 'autoencoder32-1',\n",
        "            'pca16-1', 'autoencoder16-1', 'pca30-1', 'autoencoder30-1', 'pca12-1', 'autoencoder12-1']\n",
        "dataset: 'mnist' or 'fashion_mnist'\n",
        "circuit: 'QCNN' or 'Hierarchical'\n",
        "cost_fn: 'mse' or 'cross_entropy'\n",
        "Note: when using 'mse' as cost_fn binary=\"True\" is recommended, when using 'cross_entropy' as cost_fn must be binary=\"False\".\n",
        "\"\"\"\n",
        "\n",
        "Unitaries = ['U_SU4', 'U_SU4_1D', 'U_SU4_no_pooling', 'U_9_1D']\n",
        "U_num_params = [15, 15, 15, 2]\n",
        "Encodings = ['resize256']\n",
        "dataset = 'fashion_mnist'\n",
        "classes = [0,1]\n",
        "binary = False\n",
        "cost_fn = 'cross_entropy'\n",
        "\n",
        "Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
        "#Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='Hierarchical', cost_fn=cost_fn, binary=binary)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf5bxWlkKl-E",
        "outputId": "c4d6d97a-0d99-46b9-ac53-ac8be2578a48"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4 resize256 with cross_entropy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/autograd/numpy/numpy_vjps.py:698: ComplexWarning: Casting complex values to real discards the imaginary part\n",
            "  onp.add.at(A, idx, x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration:  0  cost:  17.28581803546446\n",
            "iteration:  10  cost:  10.96374726129374\n",
            "iteration:  20  cost:  11.579323085733042\n",
            "iteration:  30  cost:  11.37859036268365\n",
            "iteration:  40  cost:  9.131590445754306\n",
            "iteration:  50  cost:  11.47688227826868\n",
            "iteration:  60  cost:  8.346484107218966\n",
            "iteration:  70  cost:  9.0920253337478\n",
            "iteration:  80  cost:  7.642636750741281\n",
            "iteration:  90  cost:  10.161205253146706\n",
            "iteration:  100  cost:  9.02328165913065\n",
            "iteration:  110  cost:  6.603783415912745\n",
            "iteration:  120  cost:  10.201872433812026\n",
            "iteration:  130  cost:  7.901327127679231\n",
            "iteration:  140  cost:  8.812901492870175\n",
            "iteration:  150  cost:  6.138780012152357\n",
            "iteration:  160  cost:  9.0787245190302\n",
            "iteration:  170  cost:  9.358299077226137\n",
            "iteration:  180  cost:  7.315595878884302\n",
            "iteration:  190  cost:  8.243754979146253\n",
            "Accuracy for U_SU4 resize256 :0.877\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4_1D resize256 with cross_entropy\n",
            "iteration:  0  cost:  18.066459356931613\n",
            "iteration:  10  cost:  15.220465779647466\n",
            "iteration:  20  cost:  12.894306839465242\n",
            "iteration:  30  cost:  11.530315751640027\n",
            "iteration:  40  cost:  7.000282831075503\n",
            "iteration:  50  cost:  7.930189581722603\n",
            "iteration:  60  cost:  9.244470512552951\n",
            "iteration:  70  cost:  10.162337558455807\n",
            "iteration:  80  cost:  7.54252607259045\n",
            "iteration:  90  cost:  7.467422067556603\n",
            "iteration:  100  cost:  10.091415266100446\n",
            "iteration:  110  cost:  8.906522499548302\n",
            "iteration:  120  cost:  7.763184887598441\n",
            "iteration:  130  cost:  7.7848001398205104\n",
            "iteration:  140  cost:  7.001678086367905\n",
            "iteration:  150  cost:  10.82755084931659\n",
            "iteration:  160  cost:  8.945842781026977\n",
            "iteration:  170  cost:  11.777173347490866\n",
            "iteration:  180  cost:  10.931181009257534\n",
            "iteration:  190  cost:  10.591651397653195\n",
            "Accuracy for U_SU4_1D resize256 :0.8885\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4_no_pooling resize256 with cross_entropy\n",
            "iteration:  0  cost:  18.242019448711698\n",
            "iteration:  10  cost:  13.131391584937067\n",
            "iteration:  20  cost:  11.450880692152964\n",
            "iteration:  30  cost:  11.082372093484452\n",
            "iteration:  40  cost:  11.652166358273366\n",
            "iteration:  50  cost:  11.657954481488094\n",
            "iteration:  60  cost:  9.931250045567161\n",
            "iteration:  70  cost:  9.569559926557865\n",
            "iteration:  80  cost:  9.18845355546614\n",
            "iteration:  90  cost:  8.748553731436875\n",
            "iteration:  100  cost:  10.546505741571252\n",
            "iteration:  110  cost:  10.026064928708031\n",
            "iteration:  120  cost:  8.73344260449322\n",
            "iteration:  130  cost:  8.873770602678626\n",
            "iteration:  140  cost:  8.692773251127877\n",
            "iteration:  150  cost:  8.009518022001965\n",
            "iteration:  160  cost:  9.85850763065568\n",
            "iteration:  170  cost:  8.302334864454139\n",
            "iteration:  180  cost:  8.127559283984958\n",
            "iteration:  190  cost:  8.126790084589587\n",
            "Accuracy for U_SU4_no_pooling resize256 :0.9265\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_9_1D resize256 with cross_entropy\n",
            "iteration:  0  cost:  17.033746918711454\n",
            "iteration:  10  cost:  17.226772088736404\n",
            "iteration:  20  cost:  17.037602816599048\n",
            "iteration:  30  cost:  16.532177831060526\n",
            "iteration:  40  cost:  16.560275761071907\n",
            "iteration:  50  cost:  16.731568222002682\n",
            "iteration:  60  cost:  16.954165076395142\n",
            "iteration:  70  cost:  16.71524752683773\n",
            "iteration:  80  cost:  16.73444512208411\n",
            "iteration:  90  cost:  16.79389945882401\n",
            "iteration:  100  cost:  16.805524761963092\n",
            "iteration:  110  cost:  16.46658047157033\n",
            "iteration:  120  cost:  16.477098375254084\n",
            "iteration:  130  cost:  16.708331142529644\n",
            "iteration:  140  cost:  16.94071694956271\n",
            "iteration:  150  cost:  16.207564793412764\n",
            "iteration:  160  cost:  16.71910466998562\n",
            "iteration:  170  cost:  16.465097251470127\n",
            "iteration:  180  cost:  16.590492502414936\n",
            "iteration:  190  cost:  16.865963506779007\n",
            "Accuracy for U_9_1D resize256 :0.762\n"
          ]
        }
      ]
    }
  ]
}